val configuration = new Configuration()val sqlContext = new SQLContext(sc)import sqlContext.implicits._
//Condition settingval startTM = args(0).toString()val entTM = args(1).toString()val fab = args(2).toString()val lotCd = args(3).toString()val oper = "'" + args(4).toString().replace(",", "','") + "'"val paramDirection = args(5).toString()val paramMethod = args(6).toStirng()val paramWindowSize = args(7).toString().toIntval paramCorrMethod = args(8).toString()val paramCorrMinMeasureCount = args(9).toString().toIntval paramCorrMinCorrValue = args(10).toString()val paramGroup = args(11).toString()val numPartition = args(12).toString().toIntval targetOper = args(4).toString().split(",")(0)val nameOfResCol = Seq("FAB","LOT_CD","AREA_CD","MAIN_OPER","OPER","OPER_DESC","PRMT_NM","CORR","TYPE","KEYS","CODE")val totalCol = Seq("DATA","RAWKEY")
val df = sqlContext.poenixTableAsDataFrame("QDW.ROA_REPWFSITE_HIS",                                           Array("TM_KEY",                                                "FAB",                                                "LOT_CD",                                                "OPER",                                                "MAIN_OPER",                                                "PRMT_NM",                                                "ALIAS_LOT_ID",                                                "WF_ID",                                                "SITE_SEQ",                                                "CHMBR_NM",                                                "UNIT_ID",                                                "MSURE_VAL",                                                "REAL_MSURE_YN",                                                "LOT_ID",                                                "AREA_CD",                                                "OPER_DESC"),                                           predicate = Some("TM_KEY BETWWEN '%s' and '%s' and LOT_CD = '%s' and OPER IN (%s)".format(starTM,endTM,fab,lotCd,Oper)),                                           conf = configuration)
df.persist()val dfToRdd = df  .map(a => a.toString)  .map(x =>{   val arrCol = x.split(",")   (arrCol(1) //fab     + "|" + arrCol(3)  //oper     + "|" + arrCol(4)  //main_oper     + "|" + arrCol(5)  //prmt_nm     + "|" + arrCol(8)  //SITE_SEQ     + "|" + arrCol(9)  //CHMBR_NM     + "|" + arrCol(10) //UNIT_ID     + "|" + arrCol(14) //AREA_CD     + "|" + arrCol(17) //MAIN_EQ    , x)  })
val reduceSortRdd = dfToRdd.reduceByKey({  _ + "!" + _}, numPartition).sortBy(_._1, true)
val rddInterpolation = reduceSortRdd.map(k => {  getInterpolation(k._2, paramDirection, paramMethod, paramWindowSize)})
val dfInterpolation = rddInterpolation.flatMap(row => {  var iterRes = Array[(String, String, String, String, String, String)]()  var a = row.map(k => {    iterRes = iterRes ++ Array((k._1,K._2,k._3,k._4,k._5,K._6))  })  iterRes.iterator}].toDf(Seq("TM_KEY",            "FAB",            "LOT_CD",            "OPER",            "MAIN_OPER",            "PRMT_NM",            "ALIAS_LOT_ID",            "WF_ID",            "SITE_SEQ",            "CHMBR_NM",            "UNIT_ID",            "MSURE_VAL",            "REAL_MSURE_YN",            "LOT_ID",            "AREA_CD",            "OPER_DESC"): _*)                                              val pivotDf = dfInterpolation.withColumn("comColumn",concat(col("FAB"),lit("|"),col("LOT_CD"), lit("|")))                                               .withColumn("Msure_VAL", 'MSURE_VAL.cast("Double"))                                               .groupBy("ALIAS_LOT_ID","WF_ID","SITE_SEQ")                                               .pivot"comColum")                                               .max("MSURE_VAL")
df.registerTempTable("DF")val t = sqlContext.sql("SELECT distinct concat(FAB,'|',LOT_CD,'|',AREA_CD,'|',MAIN_OPER,'|',OPER,'|',OPER_DESC,'|',PRMT_NM ) FROM DF WHERE OPER = '%s'".format(targetOper)).na.drop("any").collect().mkString(",")val c = sqlContext.sql("").na.drop("any").collect().mkString(",")
val targetCol = sc.parallelize(t.split(","))val compareCol = sc.parallelize(c.split(","))df.unpersist()
val cartesianCol = targetCol.cartesian(compareCol)var totalCorrList = Array[(String, String, String, String)]()
pivotDf.persist()try {  cartesianCol.collect().map(k => {    val targetCol = k._1.replaceAll("\\[|]","")    val compareCol = k._2.replaceAll("\\[|]","")    val toCol = pivotDf.select(targetCol, compareCol).na.drop("any")    toCol.persist()    val listTargetCol = toCol.rdd.map(r => (r(0))).collect().mkString("|")    val listCompareCol = toCol.rdd.map(r => (r(1))).collect().mkString("|")    val countOfMatch = listTargetCol.split("\\|").length    toCol.unpersist()    if((listTargetCol != "") & (listCompareCol != "") & (countOfMatch >= paramCorrMinMeasureCount)) {      totalCorrList = totalCorrList :+ (targetCol, compareCol, listTargetCol, listCompareCol)    } else {}  })} catch {  case e: AnalysisException => {    val resultJson = ""    println("[ROAAnalysis.scala] resultJson = " + resultJson)    return resultJson   }  case NonFatal(e) =>{    val resultJson = ""    printLn("")    return resultJson  }} finally {  pivotDf.unpersist()}                     val doCorrel = sc.parallelize(totalCorrList)val resDeCorrel = doCorrel.map(k => {  val correlation: Double = getCorrelVal(k._3, k._4, paramCorrMethod)  val arrTargetCol = k._2.split("\\|")  (    arrTargetCol(0), //FAB    arrTargetCol(1), //LOT_CD    arrTargetCol(2), //AREA_CD    arrTargetCol(3), //MAIN_OPER    arrTargetCol(4), //OPER    arrTargetCol(5), //OPER_DESC    arrTargetCol(6), //PRMT_NM    correlation, //CORR    "COMPARE", //TYPE    K._1, //KEYS    "ROA-000" //CODE    )})
val resTarget = targetCol.map(k =>{  val arrCol = k.split("\\|")  (arrCol(0).replaceAll("\\[|]",""), //FAB   arrCol(1), //LOT_CD   arrCol(2), //AREA_CD   arrCol(3), //MAIN_OPER   arrCol(4), //OPER   arrCol(5), //OPER_DESC   arrCol(6).replaceAll("\\[|]", ""), //PRMT_NM   0.0, //CORR   "TARGET", //TYPE   (l).replaceAll("\\[|]", ""), //KEYS   "ROA-000" //CODDE   )})
val dfResult = (resTarget.union(resDeCorrel)).toDF(nameOfResCol:_*)  .na.drop()  .filter(col("OPER_DESC") !== "null")
dfResult.registerTempTable("Result")val operLists = sqlContext.sql("SELECT DISTINCT OPER, PRMT_NM FROM Result")  .collect()  .mkString("') or '")  .replace("[", "OPER = '")  .replace("]", "")  .replace(",", "' and PRMT_NM = '")
dfInterpolation.registerTempTable("ROWDF")val rawdfs = sqlContext.sql("SELECT * FROM ROWDF WHERE (%s')".format(operList))
val rawpivotDf = rawdfsparamGroup match {  case "site" => {    rawpivotDf = rawdfs.withColumn("REAL_MSURE_YN", when(col("REAL_MSURE_YN") === "Y", 1).otherwise(0))                  .withColumn("OperColum", concat(col("OPER"), lit("_"), col("PRMT_NM"))                  .withColumn("MSURE_VAL", 'MSURE_VAL.cast("Double"))                  .groupBy("FAB","LOT_CD","ALIAS_LOT_ID","WF_ID","SITE_SEQ")                  .pivot("OperColumn")                  .agg(max("MSURE_VAL"), max("REAL_MSURE_YN"))  }  case "wafer" => {      }}
val corrData = dfResult.toJSON.toDF("DATA").withColumn("RAWKEY", lit(1))val rawData = rawprvotDf.toJSON.toDF("DATA"0.withColumn("RAWKEY", lit(2))                                     val totalData = corrData.unionAll(rawData)
val nameOfCompare = Seq("FAB","LOT_CD","AREA_CD","MAIN_OPER","OPER","OPER_DESC","PRMT_NM","CORR","KEYS")                     
return totalData
